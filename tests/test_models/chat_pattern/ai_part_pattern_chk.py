#!/usr/bin/env python3
"""
Direct Import AI Pattern Checker
Simple approach - just import what we need directly
"""

import os
import re
import csv
import json
import logging
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict
import random

# Simple path setup
current_dir = os.path.dirname(os.path.abspath(__file__))
base_dir = os.path.abspath(os.path.join(current_dir, '..', '..', '..'))
sys.path.insert(0, base_dir)

print(f"[SETUP] Added to path: {base_dir}")

# Direct imports - no try/except, just import them
import anthropic
from modules.configuration.config_env import DatabaseConfig
from modules.search import SearchIntent, IntentPattern
from modules.emtacdb.emtacdb_fts import Part
from modules.configuration.config import ANTHROPIC_API_KEY, DATABASE_URL
from sqlalchemy.orm import Session

print("[OK] All modules imported successfully!")
print(f"[OK] DATABASE_URL: {DATABASE_URL[:50]}...")
print(f"[OK] ANTHROPIC_API_KEY: {ANTHROPIC_API_KEY[:8]}...")


@dataclass
class SimulatedQuery:
    """A query generated by AI to simulate user behavior."""
    original_part: str
    part_id: int
    generated_query: str
    query_type: str
    expected_intent: str
    confidence: float


@dataclass
class TestResult:
    """Result of testing a simulated query against patterns."""
    query: SimulatedQuery
    pattern_id: int
    pattern_text: str
    intent_name: str
    matched: bool
    extracted_value: Optional[str]
    confidence_score: float
    response_time_ms: float


class AIUserSimulator:
    """Generates realistic user queries using Anthropic's AI."""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or ANTHROPIC_API_KEY
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found")

        self.client = anthropic.Anthropic(api_key=self.api_key)

        # Setup logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)

        # Database setup
        self.db_config = DatabaseConfig()
        self.session = self.db_config.get_main_session()
        print("[OK] Database connection established")

    def generate_user_queries(self, parts: List[Dict], queries_per_part: int = 3) -> List[SimulatedQuery]:
        """Generate realistic user queries for the given parts using AI."""
        all_queries = []

        # Process parts in small batches
        batch_size = 3
        for i in range(0, len(parts), batch_size):
            batch = parts[i:i + batch_size]
            batch_queries = self._generate_batch_queries(batch, queries_per_part)
            all_queries.extend(batch_queries)
            self.logger.info(f"Generated queries for parts {i + 1}-{min(i + batch_size, len(parts))}")

        return all_queries

    def _generate_batch_queries(self, parts_batch: List[Dict], queries_per_part: int) -> List[SimulatedQuery]:
        """Generate queries for a batch of parts."""
        parts_info = []
        for part in parts_batch:
            parts_info.append({
                'part_number': part['part_number'],
                'name': part.get('name', 'Unknown'),
                'manufacturer': part.get('oem_mfg', 'Unknown'),
                'id': part['id']
            })

        prompt = self._create_query_generation_prompt(parts_info, queries_per_part)

        try:
            response = self.client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=3000,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}]
            )

            queries = self._parse_ai_response(response.content[0].text, parts_batch)
            return queries

        except Exception as e:
            self.logger.error(f"Error generating queries with AI: {e}")
            return self._generate_template_queries(parts_batch, queries_per_part)

    def _create_query_generation_prompt(self, parts_info: List[Dict], queries_per_part: int) -> str:
        """Create a prompt for the AI to generate realistic user queries."""
        parts_list = "\n".join([f"- {p['part_number']}: {p['name']}" for p in parts_info])

        prompt = f"""Generate {queries_per_part} realistic maintenance worker queries for EACH part:

{parts_list}

Create varied queries for different scenarios:
- Direct: "find part A115957"
- Conversational: "I need A115957 urgently" 
- Brief: "A115957 location"
- Descriptive: "show me rebuild valve kit"

Return as JSON:
```json
[
  {{
    "part_number": "A115957",
    "part_id": 1,
    "queries": [
      {{"query": "find part A115957", "type": "direct", "intent": "FIND_PART", "confidence": 0.9}},
      {{"query": "I need A115957 ASAP", "type": "urgent", "intent": "FIND_PART", "confidence": 0.8}},
      {{"query": "show me rebuild kit", "type": "descriptive", "intent": "FIND_PART", "confidence": 0.6}}
    ]
  }}
]
```"""
        return prompt

    def _parse_ai_response(self, response_text: str, parts_batch: List[Dict]) -> List[SimulatedQuery]:
        """Parse the AI response and create SimulatedQuery objects."""
        queries = []

        try:
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_text = json_match.group(1)
            else:
                json_text = response_text

            data = json.loads(json_text)

            for part_data in data:
                part_number = part_data['part_number']
                part_id = part_data['part_id']

                for query_data in part_data['queries']:
                    query = SimulatedQuery(
                        original_part=part_number,
                        part_id=part_id,
                        generated_query=query_data['query'],
                        query_type=query_data['type'],
                        expected_intent=query_data['intent'],
                        confidence=query_data['confidence']
                    )
                    queries.append(query)

            return queries

        except Exception as e:
            self.logger.warning(f"Could not parse AI response: {e}")
            return self._generate_template_queries(parts_batch, 3)

    def _generate_template_queries(self, parts_batch: List[Dict], queries_per_part: int) -> List[SimulatedQuery]:
        """Fallback template generation."""
        templates = [
            ("find part {part}", "direct", "FIND_PART", 0.9),
            ("search for {part}", "direct", "FIND_PART", 0.8),
            ("I need {part}", "conversational", "FIND_PART", 0.7),
            ("{part} urgent", "urgent", "FIND_PART", 0.6),
        ]

        queries = []
        for part in parts_batch:
            part_number = part['part_number']
            for template, query_type, intent, confidence in templates[:queries_per_part]:
                query = SimulatedQuery(
                    original_part=part_number,
                    part_id=part['id'],
                    generated_query=template.format(part=part_number),
                    query_type=query_type,
                    expected_intent=intent,
                    confidence=confidence
                )
                queries.append(query)

        return queries

    def test_queries_against_patterns(self, queries: List[SimulatedQuery]) -> List[TestResult]:
        """Test the generated queries against database patterns."""
        patterns = self._load_patterns()
        if not patterns:
            self.logger.error("No patterns loaded")
            return []

        results = []
        total_tests = len(queries) * len(patterns)
        test_count = 0

        self.logger.info(f"Testing {len(queries)} queries against {len(patterns)} patterns...")

        for query in queries:
            for pattern in patterns:
                start_time = datetime.now()

                matched, extracted = self._test_pattern_match(
                    pattern['compiled_regex'],
                    query.generated_query
                )

                end_time = datetime.now()
                response_time = (end_time - start_time).total_seconds() * 1000

                confidence_score = self._calculate_confidence(
                    matched, extracted, query.original_part, query.confidence
                )

                result = TestResult(
                    query=query,
                    pattern_id=pattern['id'],
                    pattern_text=pattern['pattern_text'],
                    intent_name=pattern['intent_name'],
                    matched=matched,
                    extracted_value=extracted,
                    confidence_score=confidence_score,
                    response_time_ms=response_time
                )

                results.append(result)
                test_count += 1

                if test_count % 20 == 0:
                    progress = (test_count / total_tests) * 100
                    self.logger.info(f"Progress: {progress:.1f}%")

        return results

    def _load_patterns(self) -> List[Dict[str, Any]]:
        """Load active patterns from database."""
        try:
            query = self.session.query(
                IntentPattern.id,
                IntentPattern.pattern_text,
                IntentPattern.pattern_type,
                SearchIntent.name.label('intent_name')
            ).join(
                SearchIntent, IntentPattern.intent_id == SearchIntent.id
            ).filter(
                IntentPattern.is_active == True,
                SearchIntent.is_active == True
            )

            patterns = []
            for row in query.all():
                try:
                    compiled_regex = re.compile(row.pattern_text, re.IGNORECASE)
                    patterns.append({
                        'id': row.id,
                        'pattern_text': row.pattern_text,
                        'pattern_type': row.pattern_type,
                        'intent_name': row.intent_name,
                        'compiled_regex': compiled_regex
                    })
                except re.error:
                    continue

            return patterns

        except Exception as e:
            self.logger.error(f"Error loading patterns: {e}")
            return []

    def _test_pattern_match(self, compiled_regex: re.Pattern, query: str) -> Tuple[bool, Optional[str]]:
        """Test if a pattern matches a query."""
        match = compiled_regex.search(query)
        if match:
            extracted = match.group(1) if match.groups() else match.group(0)
            return True, extracted
        return False, None

    def _calculate_confidence(self, matched: bool, extracted: Optional[str],
                              expected_part: str, query_confidence: float) -> float:
        """Calculate confidence score for the match."""
        if not matched:
            return 0.0
        if not extracted:
            return query_confidence * 0.5
        if extracted.upper() == expected_part.upper():
            return query_confidence
        elif expected_part.upper().startswith(extracted.upper()):
            return query_confidence * 0.8
        else:
            return query_confidence * 0.6

    def save_results(self, results: List[TestResult], filename: str = None) -> str:
        """Save detailed results to CSV."""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ai_simulation_results_{timestamp}.csv"

        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                'query_text', 'query_type', 'original_part',
                'pattern_id', 'pattern_text', 'intent_name', 'matched',
                'extracted_value', 'confidence_score'
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for result in results:
                writer.writerow({
                    'query_text': result.query.generated_query,
                    'query_type': result.query.query_type,
                    'original_part': result.query.original_part,
                    'pattern_id': result.pattern_id,
                    'pattern_text': result.pattern_text,
                    'intent_name': result.intent_name,
                    'matched': result.matched,
                    'extracted_value': result.extracted_value,
                    'confidence_score': result.confidence_score,
                })

        self.logger.info(f"Results saved to: {filename}")
        return filename

    def close(self):
        """Clean up resources."""
        if self.session:
            self.session.close()


def main():
    """Main execution function."""
    print("AI User Simulator for Pattern Testing")
    print("=" * 50)

    if not ANTHROPIC_API_KEY:
        print("[ERROR] ANTHROPIC_API_KEY not found")
        return

    print(f"[OK] API key available: {ANTHROPIC_API_KEY[:8]}...")

    try:
        simulator = AIUserSimulator(ANTHROPIC_API_KEY)
        print("[OK] AI User Simulator initialized")

        # Load sample parts (start small)
        print("\nLoading parts from database...")
        parts_query = simulator.session.query(Part).filter(
            Part.part_number.isnot(None)
        ).limit(3)  # Just 3 parts for testing

        parts = []
        for part in parts_query.all():
            parts.append({
                'id': part.id,
                'part_number': part.part_number,
                'name': part.name or 'Unknown',
                'oem_mfg': part.oem_mfg or 'Unknown',
                'notes': part.notes or ''
            })

        print(f"[OK] Loaded {len(parts)} parts for testing")

        # Show the parts
        print("\nParts being tested:")
        for i, part in enumerate(parts, 1):
            print(f"  {i}. {part['part_number']}: {part['name']}")

        # Generate queries using AI
        print(f"\n[AI] Generating realistic queries...")
        queries = simulator.generate_user_queries(parts, queries_per_part=3)
        print(f"[OK] Generated {len(queries)} queries")

        # Show some examples
        print("\nExample AI-generated queries:")
        for i, query in enumerate(queries[:6], 1):
            print(f"  {i}. '{query.generated_query}' ({query.query_type})")

        # Test against patterns
        print(f"\n[TEST] Testing against database patterns...")
        results = simulator.test_queries_against_patterns(queries)
        print(f"[OK] Completed {len(results)} tests")

        # Save results
        filename = simulator.save_results(results)

        # Quick analysis
        total_matches = sum(1 for r in results if r.matched)
        high_confidence = sum(1 for r in results if r.confidence_score > 0.8)

        print("\n" + "=" * 50)
        print("RESULTS SUMMARY")
        print("=" * 50)
        print(f"Total Tests: {len(results)}")
        print(f"Successful Matches: {total_matches}")
        print(f"Match Rate: {total_matches / len(results) * 100:.1f}%")
        print(f"High Confidence: {high_confidence}")
        print(f"Results saved to: {filename}")

        # Show successful examples
        print(f"\nSuccessful AI-Generated Queries:")
        successful = [r for r in results if r.matched and r.confidence_score > 0.8][:5]
        for example in successful:
            print(f"  '{example.query.generated_query}' -> {example.extracted_value}")

        # Check your specific pattern
        your_pattern = r"find\s+(?:this\s+|the\s+)?part\s+(?:number\s+)?([A-Za-z0-9\-\.]{3,})"
        your_results = [r for r in results if your_pattern in r.pattern_text]

        if your_results:
            your_matches = sum(1 for r in your_results if r.matched)
            print(f"\nYour 'find part' pattern: {your_matches}/{len(your_results)} matches")

    except Exception as e:
        print(f"[ERROR] Error during simulation: {e}")
        import traceback
        traceback.print_exc()

    finally:
        if 'simulator' in locals():
            simulator.close()


if __name__ == "__main__":
    main()